{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47198489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f88de79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 22 18:19:46 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 517.20       Driver Version: 517.20       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P8     7W /  N/A |     30MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     20776    C+G   ...IA GeForce Experience.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe7d0d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU Available'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "sns.set(rc={'figure.figsize':(10,6)})\n",
    "sns.set(font_scale=1.3)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import re\n",
    "import string\n",
    "import swifter\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSequenceClassification,Trainer, TrainingArguments, pipeline, AutoTokenizer\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "\"GPU Available\" if torch.cuda.is_available() else \"--Not available--\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe2522",
   "metadata": {},
   "source": [
    "# Loading training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec91c7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217364, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B2W Digital, one of the most prominent Latin American e-commerce, released the B2W-Reviews01, \n",
    "#an open corpus of product reviews with more than 130,000 user reviews. This dataset has two target features: \n",
    "#the binary label \"recommend to a friend\", and a user rate from 1 to 5 stars. Here, we only considered the user rate.\n",
    "df_file = pd.read_csv(\"data2/archive/b2w.csv\", sep=',')\n",
    "\n",
    "#The Corpus Buscapé is a large corpus of Portuguese product reviews crawled in 2013 with more than 80,000 samples \n",
    "#from the Buscapé, a product and price search website.\n",
    "#Source:  https://www.kaggle.com/datasets/fredericods/ptbr-sentiment-analysis-datasets\n",
    "\n",
    "df_file = pd.concat([df_file[['review_text','rating']],pd.read_csv(\"data2/archive/buscape.csv\", sep=',')[['review_text','rating']]])\n",
    "df_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48d135b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.373539\n",
       "4    0.303284\n",
       "1    0.140364\n",
       "3    0.127339\n",
       "2    0.055474\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file.rating.value_counts()/df_file.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c463bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_truncate(content, length=280, suffix='...'):\n",
    "    if len(content) <= length:\n",
    "        return content\n",
    "    else:\n",
    "        return ' '.join(content[:length+1].split(' ')[0:-1])\n",
    "\n",
    "\n",
    "def limpa_texto(data):\n",
    "    \n",
    "    tx = data.apply(lambda x: re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',str(x)))\n",
    "    tx = tx.swifter.apply(lambda x: re.sub('@[^\\s]+',' ',str(x))) # remover os @usuario\n",
    "    tx = tx.swifter.apply(lambda x: re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', str(x))) # remover as hashtag\n",
    "    #tx = tx.swifter.apply(lambda x: convert_emoticons(x))\n",
    "    tx = tx.swifter.apply(lambda x: re.sub(u'[^a-zA-Z0-9áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕçÇ ]', '',str(x)))\n",
    "    #tx = tx.swifter.apply(lambda x: ' '.join([token.lemma_ for token in nlp(x)]))\n",
    "    #tx = tx.swifter.apply(lambda x: ' '.join([x for x in x.split() if x not in stop_words]))\n",
    "\n",
    "    tx = tx.swifter.apply(lambda x: ''.join([i for i in x if i not in string.punctuation]))\n",
    "    tx = tx.swifter.apply(lambda x: re.sub(' +', ' ', str(x))) # remover espaços em brancos\n",
    "    tx = tx.swifter.apply(lambda x: x.strip())\n",
    "    tx = tx.swifter.apply(lambda x: x.lower())\n",
    "    tx = tx.swifter.apply(lambda x: smart_truncate(x)) #Truncate maximum twitter length 280 characters\n",
    "     \n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cfb98ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299a72757fed4f9d9d5f4d19e8bf46eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/217364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9723f558c17a4309947fa9bab621f897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/217364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811d45c401a147fdb1525335ca165fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/217364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19b8dc84e2d4c5ba84097962fbe75d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/217364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e667fd58e6549d3887dbeef445dcc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/217364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16619f869e4644c9960b0c27afaecde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/217364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc1a4d91ce34eb39149556faf7460e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/217364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c648ed288b46f68621a216e0a6e760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/217364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Preprocessing tweet text\n",
    "df_file.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_file['tweet_text_limpo'] = limpa_texto(df_file.review_text)\n",
    "\n",
    "# Transform rating to sentiment (1,2:negative(=0) 3:neutral(=2) 4,5:positive(=1))\n",
    "sentiment = {1:0,2:0,3:2,4:1,5:1}\n",
    "df_file['sentiment'] = df_file['rating'].map(sentiment).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd0c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, validation_ds = train_test_split(df_file[['tweet_text_limpo','sentiment']],test_size=0.2, \n",
    "                                           stratify = df_file['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cdeae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_ds)\n",
    "validation_ds = Dataset.from_pandas(validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad375f7",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b71436",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27b0160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"tweet_text_limpo\"], padding=True, truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1dc5ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c4343bd033487db7087be9ebee4b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_encoded = train_ds.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "856f4971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b08b13687a9436c82c2ea826ca3a1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_ds_encoded = validation_ds.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e748bd86",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5313de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 3\n",
    "model_ckpt = \"neuralmind/bert-base-portuguese-cased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b4ab5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a326106",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "logging_steps = len(train_ds_encoded) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "training_args = TrainingArguments(output_dir = model_name,\n",
    "                                    num_train_epochs = 2,\n",
    "                                    learning_rate = 2e-5,\n",
    "                                    per_device_train_batch_size = batch_size,\n",
    "                                    per_device_eval_batch_size = batch_size,\n",
    "                                    weight_decay=0.01,\n",
    "                                    evaluation_strategy = \"epoch\",\n",
    "                                    disable_tqdm = False,\n",
    "                                    logging_steps = logging_steps,\n",
    "                                    push_to_hub = False,\n",
    "                                    log_level = \"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a62b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_encoded = train_ds_encoded.rename_column('tweet_text_limpo', 'text')\n",
    "train_ds_encoded = train_ds_encoded.rename_column('sentiment', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27683eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ds_encoded = validation_ds_encoded.rename_column('tweet_text_limpo', 'text')\n",
    "validation_ds_encoded = validation_ds_encoded.rename_column('sentiment', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aeb74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling class imbalance\n",
    "class_weights = class_weight.compute_class_weight(class_weight = 'balanced',\n",
    "                                                 classes = np.unique(train_ds_encoded['label']),\n",
    "                                                 y = train_ds_encoded['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05e6a967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10870' max='10870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10870/10870 1:44:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.593700</td>\n",
       "      <td>0.560088</td>\n",
       "      <td>0.813746</td>\n",
       "      <td>0.828213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.560897</td>\n",
       "      <td>0.804729</td>\n",
       "      <td>0.822059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(class_weights.astype(np.float32)).to('cuda'))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(model = model, \n",
    "                        args = training_args,\n",
    "                        compute_metrics = compute_metrics,\n",
    "                        train_dataset = train_ds_encoded,\n",
    "                        eval_dataset = validation_ds_encoded,\n",
    "                        tokenizer = tokenizer)\n",
    "\n",
    "\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17f086",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8aaca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('./sentiment_transfer_learning_transformer_union_buscape/')\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model('./sentiment_transfer_learning_transformer_buscape/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5175c",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ff68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./sentiment_transfer_learning_transformer_buscape/\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained('./sentiment_transfer_learning_transformer_buscape/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2baf4",
   "metadata": {},
   "source": [
    "# Predicting over the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4262903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel('data2/Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bcf78e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs aleatorios</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51954</td>\n",
       "      <td>Just posted a photo @ Parque Municipal das Ara...</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4190</td>\n",
       "      <td>ncêndio em unidade de conservação na Amazônia ...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65306</td>\n",
       "      <td>Lixeiras antifauna são testadas no Parque Naci...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105536</td>\n",
       "      <td>Parque Nacional da Tijuca abriga maior preguiç...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57593</td>\n",
       "      <td>#betacaralhudosan Vídeo mostra incêndio na par...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDs aleatorios                                               text sentiment\n",
       "0           51954  Just posted a photo @ Parque Municipal das Ara...    neutro\n",
       "1            4190  ncêndio em unidade de conservação na Amazônia ...  negativo\n",
       "2           65306  Lixeiras antifauna são testadas no Parque Naci...  positivo\n",
       "3          105536  Parque Nacional da Tijuca abriga maior preguiç...  positivo\n",
       "4           57593  #betacaralhudosan Vídeo mostra incêndio na par...  negativo"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d802668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=loaded_model.model\n",
    "model = loaded_model.to('cpu')\n",
    "classifier = pipeline(\"text-classification\", model=loaded_model,tokenizer=tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c020b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(text):\n",
    "    return classifier(text, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ba8318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf76d7f29f34722b10adfde4961ea31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021e45f890584d66be35477f5fdb0d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cfced694e144dbb1c819756e097a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59dbd42ea4140e6a1ef42b6eb0c7af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61307a19f76b4c66ac3cbc6534411623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c3b23d7b6243ba911fba9296aff3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b69b2aab94447f6b9ea931244cab93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ace1d44e32e4ffd8980b2ac44c63c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test['tweet_text_limpo'] = limpa_texto(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77a93c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TROPIBIO\\mambaforge\\envs\\env_sentiment\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_test[\"preds\"] = df_test[\"tweet_text_limpo\"].apply(lambda text: make_predictions(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1e34600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probas(preds,tipo):\n",
    "    if (tipo=='positive'):\n",
    "        prob = preds[0][1]['score']\n",
    "    elif (tipo=='negative'):\n",
    "        prob = preds[0][0]['score']\n",
    "    else:\n",
    "        prob = preds[0][2]['score']\n",
    "    return prob\n",
    "\n",
    "df_test[\"positivo\"] = df_test[\"preds\"].apply(lambda text: probas(text,'positive'))\n",
    "df_test[\"negativo\"] = df_test[\"preds\"].apply(lambda text: probas(text,'negative'))\n",
    "df_test[\"neutro\"] = df_test[\"preds\"].apply(lambda text: probas(text,'neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50503d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['sentiment_pred'] = df_test[['positivo','negativo','neutro']].idxmax(axis=1)\n",
    "\n",
    "sentiment = {\n",
    "    0:\"negativo\",\n",
    "    1:\"positivo\",\n",
    "    2:\"neutro\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "189266c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.83      0.53      0.65       436\n",
      "      neutro       0.23      0.01      0.03       795\n",
      "    positivo       0.44      0.95      0.60       769\n",
      "\n",
      "    accuracy                           0.49      2000\n",
      "   macro avg       0.50      0.50      0.43      2000\n",
      "weighted avg       0.44      0.49      0.38      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test[['sentiment']], df_test[['sentiment_pred']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46622d2d",
   "metadata": {},
   "source": [
    "# Predicting final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data2/sentiment_analysis_PN.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba21e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing tweet text\n",
    "df['tweet_text_limpo'] = limpa_texto(df.text_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"preds\"] = df[\"tweet_text_limpo\"].apply(lambda text: make_predictions(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"positive\"] = df[\"preds\"].apply(lambda text: probas(text,'positive'))\n",
    "df[\"negative\"] = df[\"preds\"].apply(lambda text: probas(text,'negative'))\n",
    "df[\"neutral\"] = df[\"preds\"].apply(lambda text: probas(text,'neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df[['positive','negative','neutral']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f2ebad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicciones feitas -- Borrar\n",
    "df = pd.read_excel('sentiment_analysis_predicted_modelo_buscape.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96484d87",
   "metadata": {},
   "source": [
    "# Negative topic analysis in the six principal national parks in Brazil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a90d0a",
   "metadata": {},
   "source": [
    "## Topic model common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96a2ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TROPIBIO\\mambaforge\\envs\\env_sentiment\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\TROPIBIO\\mambaforge\\envs\\env_sentiment\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\TROPIBIO\\mambaforge\\envs\\env_sentiment\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\TROPIBIO\\mambaforge\\envs\\env_sentiment\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "No sentence-transformers model found with name C:\\Users\\TROPIBIO/.cache\\torch\\sentence_transformers\\neuralmind_bert-base-portuguese-cased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\TROPIBIO/.cache\\torch\\sentence_transformers\\neuralmind_bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Topic model\n",
    "from bertopic import BERTopic\n",
    "# Dimension reduction\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initiate UMAP\n",
    "umap_model = UMAP(n_neighbors=15, \n",
    "                  n_components=5, \n",
    "                  min_dist=0.0, \n",
    "                  metric='cosine', \n",
    "                  random_state=100)\n",
    "\n",
    "\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=list(stop_words), ngram_range=(1, 2))\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "representation_model = MaximalMarginalRelevance(diversity=0.2)\n",
    "\n",
    "sentence_model = SentenceTransformer(\"neuralmind/bert-base-portuguese-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7924e",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DO IGUAÇU - Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5326b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nega_igua = pd.DataFrame(df.loc[(df.sentiment=='negative') & (df.UC_text=='PARQUE NACIONAL DO IGUAÇU'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nega_igua['tweet_text_limpo'] = df_nega_igua['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b0bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nega_igua['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "#We set the parameter \"min_cluster_size=10\" due to the greater number of observations for this park\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=10, \n",
    "                        metric='euclidean', \n",
    "                        prediction_data=True)\n",
    "\n",
    "topic_model1n = BERTopic(umap_model=umap_model, \n",
    "                         hdbscan_model=hdbscan_model, \n",
    "                         language=\"multilingual\", \n",
    "                         calculate_probabilities=True, \n",
    "                         nr_topics=\"auto\",\n",
    "                         vectorizer_model=vectorizer_model,\n",
    "                         ctfidf_model=ctfidf_model, \n",
    "                         representation_model=representation_model\n",
    "                         )\n",
    "\n",
    "topics_negative_igua, probabilities_negative_igua = topic_model1n.fit_transform(df_nega_igua['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d4bb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>457</td>\n",
       "      <td>-1_chacina parque_chacina_ruralistas_compartil...</td>\n",
       "      <td>0.146993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>0_morto dentro_veado encontrado_encontrado mor...</td>\n",
       "      <td>0.087810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>1_meio parque_biodiversidade_rasgar meio_reman...</td>\n",
       "      <td>0.083950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>227</td>\n",
       "      <td>2_táxis_iguaçu decisão_proíbe_taxis</td>\n",
       "      <td>0.073014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>3_atropelada_jaguatirica_próximo parque_atrope...</td>\n",
       "      <td>0.047604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "0     -1    457  -1_chacina parque_chacina_ruralistas_compartil...    0.146993\n",
       "1      0    273  0_morto dentro_veado encontrado_encontrado mor...    0.087810\n",
       "2      1    261  1_meio parque_biodiversidade_rasgar meio_reman...    0.083950\n",
       "3      2    227                2_táxis_iguaçu decisão_proíbe_taxis    0.073014\n",
       "4      3    148  3_atropelada_jaguatirica_próximo parque_atrope...    0.047604"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_igua = topic_model1n.get_topic_info().iloc[0:5,]\n",
    "\n",
    "df_topic_igua['Percentage'] = topic_model1n.get_topic_info().Count/topic_model1n.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_igua"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b181449",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DO IGUAÇU - No Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d89d2acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonega_igua = pd.DataFrame(df.loc[df.sentiment.isin(['positive','neutral']) & (df.UC_text=='PARQUE NACIONAL DO IGUAÇU'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nonega_igua['tweet_text_limpo'] = df_nonega_igua['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a659435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nonega_igua['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "#We set the parameter \"min_cluster_size=10\" due to the greater number of observations for this park\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=30, \n",
    "                           metric='euclidean', \n",
    "                           prediction_data=True)\n",
    "\n",
    "topic_model1nn = BERTopic(umap_model=umap_model, \n",
    "                          hdbscan_model=hdbscan_model, \n",
    "                          language=\"multilingual\", \n",
    "                          calculate_probabilities=True, \n",
    "                          nr_topics=\"auto\",\n",
    "                          vectorizer_model=vectorizer_model,\n",
    "                          ctfidf_model=ctfidf_model, \n",
    "                          representation_model=representation_model\n",
    "                          )\n",
    "\n",
    "topics_nonegative_igua, probabilities_nonegative_igua = topic_model1nn.fit_transform(df_nonega_igua['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "712577c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>5548</td>\n",
       "      <td>-1_vista_iguaçú_itaipu_çu parque</td>\n",
       "      <td>0.261562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1448</td>\n",
       "      <td>0_sobe domingo_iguaçu sobe_sobe_visitantes páscoa</td>\n",
       "      <td>0.068266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>761</td>\n",
       "      <td>1_milhão visitantes_iguaçu recebeu_recebeu_pes...</td>\n",
       "      <td>0.035878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>732</td>\n",
       "      <td>2_pr im_pr others_at parque_others im</td>\n",
       "      <td>0.034510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>651</td>\n",
       "      <td>3_iguaçu reajusta_reajusta_reajusta valor_ingr...</td>\n",
       "      <td>0.030692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "0     -1   5548                   -1_vista_iguaçú_itaipu_çu parque    0.261562\n",
       "1      0   1448  0_sobe domingo_iguaçu sobe_sobe_visitantes páscoa    0.068266\n",
       "2      1    761  1_milhão visitantes_iguaçu recebeu_recebeu_pes...    0.035878\n",
       "3      2    732              2_pr im_pr others_at parque_others im    0.034510\n",
       "4      3    651  3_iguaçu reajusta_reajusta_reajusta valor_ingr...    0.030692"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_igua_nn = topic_model1nn.get_topic_info().iloc[0:5,]\n",
    "\n",
    "df_topic_igua_nn['Percentage'] = topic_model1nn.get_topic_info().Count/topic_model1nn.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_igua_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70551afe",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DA TIJUCA - Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "643e6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nega_tiju = pd.DataFrame(df.loc[(df.sentiment=='negative') & (df.UC_text=='PARQUE NACIONAL DA TIJUCA'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nega_tiju['tweet_text_limpo'] = df_nega_tiju['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b68655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nega_tiju['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=6, \n",
    "                        metric='euclidean', \n",
    "                        prediction_data=True)\n",
    "\n",
    "topic_model2n = BERTopic(umap_model=umap_model, \n",
    "                         hdbscan_model=hdbscan_model, \n",
    "                         language=\"multilingual\", \n",
    "                         calculate_probabilities=True, \n",
    "                         nr_topics=\"auto\",\n",
    "                         vectorizer_model=vectorizer_model,\n",
    "                         ctfidf_model=ctfidf_model, \n",
    "                         representation_model=representation_model)\n",
    "\n",
    "topics_negative_tiju, probabilities_negative_tiju = topic_model2n.fit_transform(df_nega_tiju['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66571201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>0_ambiental_proteção ambiental_proteção_área</td>\n",
       "      <td>0.194561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1_tijuca icmbio_tijuca floresta_icmbio_floresta</td>\n",
       "      <td>0.103556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>2_46_46 anos_mora 46_idoso mora</td>\n",
       "      <td>0.092050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>3_assaltados parque_assaltados_visitantes assa...</td>\n",
       "      <td>0.091004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "1      0    186       0_ambiental_proteção ambiental_proteção_área    0.194561\n",
       "2      1     99    1_tijuca icmbio_tijuca floresta_icmbio_floresta    0.103556\n",
       "3      2     88                    2_46_46 anos_mora 46_idoso mora    0.092050\n",
       "4      3     87  3_assaltados parque_assaltados_visitantes assa...    0.091004"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_tiju = topic_model2n.get_topic_info().iloc[1:5,]\n",
    "\n",
    "df_topic_tiju['Percentage'] = topic_model2n.get_topic_info().Count/topic_model2n.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_tiju"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587a828",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DA TIJUCA - No Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33927f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonega_tiju = pd.DataFrame(df.loc[df.sentiment.isin(['positive','neutral']) & (df.UC_text=='PARQUE NACIONAL DA TIJUCA'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nonega_tiju['tweet_text_limpo'] = df_nonega_tiju['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe6c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nonega_tiju['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "#We set the parameter \"min_cluster_size=12\" due to the greater number of observations for this park\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=12, \n",
    "                           metric='euclidean', \n",
    "                           prediction_data=True)\n",
    "\n",
    "topic_model2nn = BERTopic(umap_model=umap_model, \n",
    "                          hdbscan_model=hdbscan_model, \n",
    "                          language=\"multilingual\", \n",
    "                          calculate_probabilities=True, \n",
    "                          nr_topics=\"auto\",\n",
    "                          vectorizer_model=vectorizer_model,\n",
    "                          ctfidf_model=ctfidf_model, \n",
    "                          representation_model=representation_model\n",
    "                          )\n",
    "\n",
    "topics_nonegative_tiju, probabilities_nonegative_tiju = topic_model2nn.fit_transform(df_nonega_tiju['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82d81bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2565</td>\n",
       "      <td>-1_fica_aqui_lindo_natureza</td>\n",
       "      <td>0.265116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>0_ir_ir parque_ponto alto_trilha parque</td>\n",
       "      <td>0.045478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>418</td>\n",
       "      <td>1_publicar foto_acabou publicar_acabou_foto pa...</td>\n",
       "      <td>0.043204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>316</td>\n",
       "      <td>2_rj im_tijuca in_in rio_at parque</td>\n",
       "      <td>0.032661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>312</td>\n",
       "      <td>3_tijuca parque_viii_tijuca ix_tijuca viii</td>\n",
       "      <td>0.032248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "0     -1   2565                        -1_fica_aqui_lindo_natureza    0.265116\n",
       "1      0    440            0_ir_ir parque_ponto alto_trilha parque    0.045478\n",
       "2      1    418  1_publicar foto_acabou publicar_acabou_foto pa...    0.043204\n",
       "3      2    316                 2_rj im_tijuca in_in rio_at parque    0.032661\n",
       "4      3    312         3_tijuca parque_viii_tijuca ix_tijuca viii    0.032248"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_tiju_nn = topic_model2nn.get_topic_info().iloc[0:5,]\n",
    "\n",
    "df_topic_tiju_nn['Percentage'] = topic_model2nn.get_topic_info().Count/topic_model2nn.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_tiju_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262f4ea",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DO ITATIAIA - Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83f9849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nega_ita = pd.DataFrame(df.loc[(df.sentiment=='negative') & (df.UC_text=='PARQUE NACIONAL DO ITATIAIA'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nega_ita['tweet_text_limpo'] = df_nega_ita['tweet_text_limpo'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efab8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nega_ita['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=6, \n",
    "                        metric='euclidean', \n",
    "                        prediction_data=True)\n",
    "\n",
    "topic_model2n = BERTopic(umap_model=umap_model, \n",
    "                         hdbscan_model=hdbscan_model, \n",
    "                         language=\"multilingual\", \n",
    "                         calculate_probabilities=True, \n",
    "                         nr_topics=\"auto\",\n",
    "                         vectorizer_model=vectorizer_model,\n",
    "                         ctfidf_model=ctfidf_model, \n",
    "                         representation_model=representation_model)\n",
    "\n",
    "topics_negative_ita, probabilities_negative_ita = topic_model2n.fit_transform(df_nega_ita['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70a47b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>0_assista_itatiaia assista_vídeo mostra_mostra...</td>\n",
       "      <td>0.207378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>1_queda árvore_árvore_turistas parque_saída tu...</td>\n",
       "      <td>0.081755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>2_graus_temperatura_zero_abaixo zero</td>\n",
       "      <td>0.072782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>3_sul rio_itatiaia sul_sul_atinge</td>\n",
       "      <td>0.065803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "1      0    208  0_assista_itatiaia assista_vídeo mostra_mostra...    0.207378\n",
       "2      1     82  1_queda árvore_árvore_turistas parque_saída tu...    0.081755\n",
       "3      2     73               2_graus_temperatura_zero_abaixo zero    0.072782\n",
       "4      3     66                  3_sul rio_itatiaia sul_sul_atinge    0.065803"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_ita = topic_model2n.get_topic_info().iloc[1:5,]\n",
    "\n",
    "df_topic_ita['Percentage'] = topic_model2n.get_topic_info().Count/topic_model2n.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_ita"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da87a6b",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DO ITATIAIA - No Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "718ca586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonega_ita = pd.DataFrame(df.loc[df.sentiment.isin(['positive','neutral']) & (df.UC_text=='PARQUE NACIONAL DO ITATIAIA'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nonega_ita['tweet_text_limpo'] = df_nonega_ita['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdc7a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nonega_ita['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "#We set the parameter \"min_cluster_size=12\" due to the greater number of observations for this park\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=12, \n",
    "                           metric='euclidean', \n",
    "                           prediction_data=True)\n",
    "\n",
    "topic_model2nn = BERTopic(umap_model=umap_model, \n",
    "                          hdbscan_model=hdbscan_model, \n",
    "                          language=\"multilingual\", \n",
    "                          calculate_probabilities=True, \n",
    "                          nr_topics=\"auto\",\n",
    "                          vectorizer_model=vectorizer_model,\n",
    "                          ctfidf_model=ctfidf_model, \n",
    "                          representation_model=representation_model\n",
    "                          )\n",
    "\n",
    "topics_nonegative_ita, probabilities_nonegative_ita = topic_model2nn.fit_transform(df_nonega_ita['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dfe8dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1667</td>\n",
       "      <td>-1_travessia_dias_sul rio_costa verde</td>\n",
       "      <td>0.211871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>763</td>\n",
       "      <td>0_tv rio_rio sul_morre voluntários_antigos</td>\n",
       "      <td>0.096975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>602</td>\n",
       "      <td>1_lá_vou_ir_pro</td>\n",
       "      <td>0.076512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>251</td>\n",
       "      <td>2_santuário ecológico_itatiaia verdadeiro_verd...</td>\n",
       "      <td>0.031901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>240</td>\n",
       "      <td>3_primeiro parque_anos parque_1937_criado</td>\n",
       "      <td>0.030503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "0     -1   1667              -1_travessia_dias_sul rio_costa verde    0.211871\n",
       "1      0    763         0_tv rio_rio sul_morre voluntários_antigos    0.096975\n",
       "2      1    602                                    1_lá_vou_ir_pro    0.076512\n",
       "3      2    251  2_santuário ecológico_itatiaia verdadeiro_verd...    0.031901\n",
       "4      3    240          3_primeiro parque_anos parque_1937_criado    0.030503"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_ita_nn = topic_model2nn.get_topic_info().iloc[0:5,]\n",
    "\n",
    "df_topic_ita_nn['Percentage'] = topic_model2nn.get_topic_info().Count/topic_model2nn.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_ita_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e66568",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DA CHAPADA DOS VEADEIROS - Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7c3269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nega_chapa = pd.DataFrame(df.loc[(df.sentiment=='negative') & (df.UC_text=='PARQUE NACIONAL DA CHAPADA DOS VEADEIROS'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nega_chapa['tweet_text_limpo'] = df_nega_chapa['tweet_text_limpo'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d0bc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nega_chapa['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=4, \n",
    "                        metric='euclidean', \n",
    "                        prediction_data=True)\n",
    "\n",
    "topic_model2n = BERTopic(umap_model=umap_model, \n",
    "                         hdbscan_model=hdbscan_model, \n",
    "                         language=\"multilingual\", \n",
    "                         calculate_probabilities=True, \n",
    "                         nr_topics=\"auto\",\n",
    "                         vectorizer_model=vectorizer_model,\n",
    "                         ctfidf_model=ctfidf_model, \n",
    "                         representation_model=representation_model)\n",
    "\n",
    "topics_negative_chapa, probabilities_negative_chapa = topic_model2n.fit_transform(df_nega_chapa['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "111c86bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0_publicar_acabou publicar_publicar foto_veade...</td>\n",
       "      <td>0.146096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>1_quase 15_dosveadeiros incêndio_dosveadeiros_...</td>\n",
       "      <td>0.125105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2_casa perigo_carinhas habitam_carinhas_todos ...</td>\n",
       "      <td>0.041982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>3_saudades_filtro_nada_veadeiros saudades</td>\n",
       "      <td>0.032746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "1      0    174  0_publicar_acabou publicar_publicar foto_veade...    0.146096\n",
       "2      1    149  1_quase 15_dosveadeiros incêndio_dosveadeiros_...    0.125105\n",
       "3      2     50  2_casa perigo_carinhas habitam_carinhas_todos ...    0.041982\n",
       "4      3     39          3_saudades_filtro_nada_veadeiros saudades    0.032746"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_chapa = topic_model2n.get_topic_info().iloc[1:5,]\n",
    "\n",
    "df_topic_chapa['Percentage'] = topic_model2n.get_topic_info().Count/topic_model2n.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_chapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353c47e",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DA CHAPADA DOS VEADEIROS - No Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b477a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonega_chapa = pd.DataFrame(df.loc[df.sentiment.isin(['positive','neutral']) & (df.UC_text=='PARQUE NACIONAL DA CHAPADA DOS VEADEIROS'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nonega_chapa['tweet_text_limpo'] = df_nonega_chapa['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2c83e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nonega_chapa['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "#We set the parameter \"min_cluster_size=10\" due to the greater number of observations for this park\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=10, \n",
    "                           metric='euclidean', \n",
    "                           prediction_data=True)\n",
    "\n",
    "topic_model2nn = BERTopic(umap_model=umap_model, \n",
    "                          hdbscan_model=hdbscan_model, \n",
    "                          language=\"multilingual\", \n",
    "                          calculate_probabilities=True, \n",
    "                          nr_topics=\"auto\",\n",
    "                          vectorizer_model=vectorizer_model,\n",
    "                          ctfidf_model=ctfidf_model, \n",
    "                          representation_model=representation_model\n",
    "                          )\n",
    "\n",
    "topics_nonegative_chapa, probabilities_nonegative_chapa = topic_model2nn.fit_transform(df_nonega_chapa['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48f2a116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1174</td>\n",
       "      <td>-1_anos_sobre_fica_trilha</td>\n",
       "      <td>0.297970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>0_mil hectares_hectares_mil_decreto</td>\n",
       "      <td>0.062437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>1_incêndio parque_combate_combate incêndio_inc...</td>\n",
       "      <td>0.045431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "      <td>2_veadeiros concedido_concedido_concedido inic...</td>\n",
       "      <td>0.044924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>3_in alto_veadeiros in_im at_im</td>\n",
       "      <td>0.043147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "0     -1   1174                          -1_anos_sobre_fica_trilha    0.297970\n",
       "1      0    246                0_mil hectares_hectares_mil_decreto    0.062437\n",
       "2      1    179  1_incêndio parque_combate_combate incêndio_inc...    0.045431\n",
       "3      2    177  2_veadeiros concedido_concedido_concedido inic...    0.044924\n",
       "4      3    170                    3_in alto_veadeiros in_im at_im    0.043147"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_chapa_nn = topic_model2nn.get_topic_info().iloc[0:5,]\n",
    "\n",
    "df_topic_chapa_nn['Percentage'] = topic_model2nn.get_topic_info().Count/topic_model2nn.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_chapa_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfeb979",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DOS LENÇÓIS MARANHENSES - Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d8dcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nega_len = pd.DataFrame(df.loc[(df.sentiment=='negative') & (df.UC_text=='PARQUE NACIONAL DOS LENÇÓIS MARANHENSES'),\n",
    "                                  'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nega_len['tweet_text_limpo'] = df_nega_len['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "176591b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nega_len['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=3, \n",
    "                        metric='euclidean', \n",
    "                        prediction_data=True)\n",
    "\n",
    "topic_model3n = BERTopic(umap_model=umap_model, \n",
    "                         hdbscan_model=hdbscan_model, \n",
    "                         language=\"multilingual\", \n",
    "                         calculate_probabilities=True, \n",
    "                         nr_topics=\"auto\",\n",
    "                         vectorizer_model=vectorizer_model,\n",
    "                         ctfidf_model=ctfidf_model, \n",
    "                         representation_model=representation_model)\n",
    "\n",
    "topics_negative_len, probabilities_negative_len = topic_model3n.fit_transform(df_nega_len['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bf53d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>46</td>\n",
       "      <td>-1_maranhenses_filme_maranhenses alguém_requer...</td>\n",
       "      <td>0.141104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0_quadriciclos parque_quadriciclos_trânsito qu...</td>\n",
       "      <td>0.368098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1_projeto_limites_limites parque_altera</td>\n",
       "      <td>0.254601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2_estradas_risco parque_põem risco_põem</td>\n",
       "      <td>0.070552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3_nacional lençois_lençois_lençois maranhenses...</td>\n",
       "      <td>0.042945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4_acidente_mortos oito_mortos_quatro mortos</td>\n",
       "      <td>0.036810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "0     -1     46  -1_maranhenses_filme_maranhenses alguém_requer...    0.141104\n",
       "1      0    120  0_quadriciclos parque_quadriciclos_trânsito qu...    0.368098\n",
       "2      1     83            1_projeto_limites_limites parque_altera    0.254601\n",
       "3      2     23            2_estradas_risco parque_põem risco_põem    0.070552\n",
       "4      3     14  3_nacional lençois_lençois_lençois maranhenses...    0.042945\n",
       "5      4     12        4_acidente_mortos oito_mortos_quatro mortos    0.036810"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_len = topic_model3n.get_topic_info().iloc[0:6,]\n",
    "\n",
    "df_topic_len['Percentage'] = topic_model3n.get_topic_info().Count/topic_model3n.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6231a72",
   "metadata": {},
   "source": [
    "#### PARQUE NACIONAL DOS LENÇÓIS MARANHENSES - No Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35d3889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonega_len = pd.DataFrame(df.loc[df.sentiment.isin(['positive','neutral']) & (df.UC_text=='PARQUE NACIONAL DOS LENÇÓIS MARANHENSES'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nonega_len['tweet_text_limpo'] = df_nonega_len['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "082aaae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nonega_len['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "#We set the parameter \"min_cluster_size=10\" due to the greater number of observations for this park\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=10, \n",
    "                           metric='euclidean', \n",
    "                           prediction_data=True)\n",
    "\n",
    "topic_model2nn = BERTopic(umap_model=umap_model, \n",
    "                          hdbscan_model=hdbscan_model, \n",
    "                          language=\"multilingual\", \n",
    "                          calculate_probabilities=True, \n",
    "                          nr_topics=\"auto\",\n",
    "                          vectorizer_model=vectorizer_model,\n",
    "                          ctfidf_model=ctfidf_model, \n",
    "                          representation_model=representation_model\n",
    "                          )\n",
    "\n",
    "topics_nonegative_len, probabilities_nonegative_len = topic_model2nn.fit_transform(df_nonega_len['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05055dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1160</td>\n",
       "      <td>-1_deserto_dunas_lagoas_cidade</td>\n",
       "      <td>0.299664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>0_nacional los_los lençóis_los_en</td>\n",
       "      <td>0.081374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>1_publicar_publicar foto_foto parque_amaro mar...</td>\n",
       "      <td>0.055025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>2_ma im_barreirinhas ma_im at_im</td>\n",
       "      <td>0.045208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>3_surreal landscape_landscape of_landscape_sur...</td>\n",
       "      <td>0.030483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "0     -1   1160                     -1_deserto_dunas_lagoas_cidade    0.299664\n",
       "1      0    315                  0_nacional los_los lençóis_los_en    0.081374\n",
       "2      1    213  1_publicar_publicar foto_foto parque_amaro mar...    0.055025\n",
       "3      2    175                   2_ma im_barreirinhas ma_im at_im    0.045208\n",
       "4      3    118  3_surreal landscape_landscape of_landscape_sur...    0.030483"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_len_nn = topic_model2nn.get_topic_info().iloc[0:5,]\n",
    "\n",
    "df_topic_len_nn['Percentage'] = topic_model2nn.get_topic_info().Count/topic_model2nn.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_len_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca90bf",
   "metadata": {},
   "source": [
    "## Principal topics in negative tweets for all national parks in Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4c95c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nega_all = pd.DataFrame(df.loc[(df.sentiment=='negative'),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nega_all['tweet_text_limpo'] = df_nega_all['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f30d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nega_all['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=20, \n",
    "                        metric='euclidean', \n",
    "                        prediction_data=True)\n",
    "\n",
    "topic_model_all = BERTopic(umap_model=umap_model, \n",
    "                         hdbscan_model=hdbscan_model, \n",
    "                         language=\"multilingual\", \n",
    "                         calculate_probabilities=True, \n",
    "                         nr_topics=\"auto\",\n",
    "                         vectorizer_model=vectorizer_model,\n",
    "                         ctfidf_model=ctfidf_model, \n",
    "                         representation_model=representation_model)\n",
    "\n",
    "topics_negative, probabilities_negative = topic_model_all.fit_transform(df_nega_all['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab05d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>5060</td>\n",
       "      <td>-1_pode_ão_meio_hoje</td>\n",
       "      <td>0.275179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1038</td>\n",
       "      <td>0_ba meses_pascoal ba_meses icmbio_icmbio incê...</td>\n",
       "      <td>0.056450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>586</td>\n",
       "      <td>1_diamantina incêndio_gigantesco consumindo_in...</td>\n",
       "      <td>0.031869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>381</td>\n",
       "      <td>2_colono_estrada colono_aceitamos_atlântica bi...</td>\n",
       "      <td>0.020720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>377</td>\n",
       "      <td>3_incêndio fecha_cipó minas_gerais incêndio_fe...</td>\n",
       "      <td>0.020503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>375</td>\n",
       "      <td>4_pra_noronha_cara_ministro</td>\n",
       "      <td>0.020394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>369</td>\n",
       "      <td>5_tava_ir_pro_pro parque</td>\n",
       "      <td>0.020067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>355</td>\n",
       "      <td>6_óleo_manchas_manchas óleo_óleo chegam</td>\n",
       "      <td>0.019306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>332</td>\n",
       "      <td>7_proporções atinge_brasília incêndio_incêndio...</td>\n",
       "      <td>0.018055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>324</td>\n",
       "      <td>8_acabou publicar_publicar foto_publicar_foto ...</td>\n",
       "      <td>0.017620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name  Percentage\n",
       "0     -1   5060                               -1_pode_ão_meio_hoje    0.275179\n",
       "1      0   1038  0_ba meses_pascoal ba_meses icmbio_icmbio incê...    0.056450\n",
       "2      1    586  1_diamantina incêndio_gigantesco consumindo_in...    0.031869\n",
       "3      2    381  2_colono_estrada colono_aceitamos_atlântica bi...    0.020720\n",
       "4      3    377  3_incêndio fecha_cipó minas_gerais incêndio_fe...    0.020503\n",
       "5      4    375                        4_pra_noronha_cara_ministro    0.020394\n",
       "6      5    369                           5_tava_ir_pro_pro parque    0.020067\n",
       "7      6    355            6_óleo_manchas_manchas óleo_óleo chegam    0.019306\n",
       "8      7    332  7_proporções atinge_brasília incêndio_incêndio...    0.018055\n",
       "9      8    324  8_acabou publicar_publicar foto_publicar_foto ...    0.017620"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_all = topic_model_all.get_topic_info().iloc[0:10,]\n",
    "\n",
    "df_topic_all['Percentage'] = topic_model_all.get_topic_info().Count/topic_model_all.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f069eb",
   "metadata": {},
   "source": [
    "## Principal topics in no negative tweets for all national parks in Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898cb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonega_all = pd.DataFrame(df.loc[df.sentiment.isin(['positive','neutral']),\n",
    "                                   'tweet_text_limpo']).reset_index(drop=True)\n",
    "\n",
    "df_nonega_all['tweet_text_limpo'] = df_nonega_all['tweet_text_limpo'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc86623b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87852, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nonega_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ecdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate BERTopic\n",
    "embeddings = sentence_model.encode(df_nonega_all['tweet_text_limpo'], show_progress_bar=False)\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=30, \n",
    "                        metric='euclidean', \n",
    "                        prediction_data=True)\n",
    "\n",
    "topic_model_all_nn = BERTopic(umap_model=umap_model, \n",
    "                         hdbscan_model=hdbscan_model, \n",
    "                         language=\"multilingual\", \n",
    "                         calculate_probabilities=True, \n",
    "                         nr_topics=\"auto\",\n",
    "                         vectorizer_model=vectorizer_model,\n",
    "                         ctfidf_model=ctfidf_model, \n",
    "                         representation_model=representation_model)\n",
    "\n",
    "topics_nonegative, probabilities_nonegative = topic_model_all_nn.fit_transform(df_nonega_all['tweet_text_limpo'],embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59fe76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_nn_all = topic_model_all_nn.get_topic_info().iloc[0:10,]\n",
    "\n",
    "df_topic_nn_all['Percentage'] = topic_model_all_nn.get_topic_info().Count/topic_model_all_nn.get_topic_info().Count.sum()\n",
    "\n",
    "df_topic_nn_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
